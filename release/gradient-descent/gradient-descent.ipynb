{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kodlabb - Algoritmen *gradient descent*\n",
    "\n",
    "## Förkunskaper\n",
    "- Matematik 3\n",
    "- Grundkunskap - Python\n",
    "- Grundkunskap - Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduktion\n",
    "En dator lyder instruktioner till punkt och pricka. Men vad händer om en dator ombeds att träna upp en förmåga att ta egna beslut? Det är just det som maskininlärning (ML) och artificiell intelligens (AI) handlar om. AI tränas ofta genom att minimera någon form av fel den gör och *gradient descent* (GD) som vi kommer undersöka och implementera är en vanlig algoritm för detta.\n",
    "\n",
    "[![](https://img.youtube.com/vi/jAu1ZsTCA64/maxresdefault.jpg)](https://www.youtube.com/watch?v=jAu1ZsTCA64)\n",
    "*YouTube: En artificiell intelligens har besegrat Dota2 proffs i dueller (Augusti 2017).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studiestund 1\n",
    "\n",
    "Innan vi kommer igång behöver vi utvidga våra kunskaper från Matte 3 och lära oss om *funktioner av flera variabler*, *partiell derivata* och *gradienter*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Funktioner av flera variabler, partiell derivata och gradienter\n",
    "\n",
    "En *definitionsmängd* eller en *domän* är inom matematiken mängden av alla möjliga argument eller invärden för en funktion. Funktioner av flera variabler såsom $g$ och $h$ nedan har flerdimensionella definitionsmängder.\n",
    "\n",
    "\\begin{array}{rl rl}\n",
    "f(x)     &=x^2         & f(2)     &=4  \\\\\n",
    "g(x,y)   &=x^2+y^2     & f(2,3)   &=13 \\\\\n",
    "h(x,y,z) &=x^2+y^2+z^2 & f(2,3,4) &=29 \\\\\n",
    "\\end{array}\n",
    "\n",
    "Ibland är det bra att veta hur funktionsvärdet förändras om vi förflyttar oss i definitionsmängden. För varje riktning vi kan röra oss inom definitionsmängden kan vi beräkna en *partiell derivata*. En *gradient* är en vektor vars komponenter består av de partiella derivatorna. Titta nu på följande film och besvara därefter några kontrollfrågor.\n",
    "\n",
    "[![](https://img.youtube.com/vi/GkB4vW16QHI/maxresdefault.jpg)](https://www.youtube.com/watch?v=GkB4vW16QHI)\n",
    "*YouTube: Du får lära dig om [partiell derivata](https://sv.wikipedia.org/wiki/Partiell_derivata) som beteckas $\\frac{\\partial f}{\\partial x}$ och $\\frac{\\partial f}{\\partial y}$ och om [gradienter](https://sv.wikipedia.org/wiki/Gradient) som betecknas $\\nabla f$.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fråga 1\n",
    "I bilden ovan ser vi en funktion $z=f(x, y)$ representerad som en yta. Föreställ dig att du är en myra på den ytan.\n",
    "- a) Beskriv vart du skulle gå om du följde gradienten och stod i en backe.\n",
    "- b) Beskriv vart du skulle gå om du följde gradienten och stod på en kulles topp.\n",
    "- c) Beskriv vad det engelska ordet *descent* betyder och gissa hur algoritmen *gradient descent* fungerar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "533a52d33d1a9aa25bd2f201fc81ba0a",
     "grade": true,
     "grade_id": "gradient_conceptuality",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementering\n",
    "Nu ska vi implementera *gradient descent* (GD). Algoritmen kommer hjälpa oss att hitta funktionens minimipunkter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kodkomplettering 1\n",
    "Du behöver en funktion att testa algoritmen på med ett antal minimipunkter.\n",
    "\n",
    "Definiera pythonfunktion `f` så att den beter sig precis som den matematiska funktionen $f(x, y)$ nedan. Använd dig av `numpy` bibliotekets funktioner `np.sin`, `np.cos` och `np.exp` tillsammans med Pythons inbyggda operator `**`.\n",
    "\n",
    "$$f(x, y) = \\sin(\\,({\\frac{x}{2}-2})^2 + (\\frac{y}{2}-2)^2\\,) \\cdot \\cos(\\,x-y+e^{-y}\\,)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from simulation import Sim\n",
    "sim = Sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "448beb176a0ce3c967ee7683e86f2605",
     "grade": false,
     "grade_id": "answer_function_definition",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    \"\"\"En funktion att undersöka som returnerar ett värde för varje input x och y.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "332b281ca62339402c9184a5d8c87576",
     "grade": true,
     "grade_id": "tests_function_definition",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: testa\n",
    "sim.setup_f(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.run(show_2d=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kodkomplettering 2\n",
    "*Gradient descent* bygger på att vi kan promenera antiparallellt (åt andra hållet) till gradienten, och gradienten byggs upp av de partiella derivatorna. Vi kan beräkna den partiella derivatan ungefärligt med ett litet värde på $h$ på följande sätt.\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x} \\approx \\frac{f(x+h, y) - f(x-h, y)}{2h}$$\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial y} \\approx \\frac{f(x, y+h) - f(x, y-h)}{2h}$$\n",
    "\n",
    "Det är ditt uppdrag att komplettera funktionerna nedan som numeriskt beräknar de partiella derivatorna för funktionen `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3874a2ddce23e977874054976b28423d",
     "grade": false,
     "grade_id": "answer_partial_derivatives",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "h = 0.001\n",
    "def df_dx(x, y):\n",
    "    \"\"\"Returns the value of the partial derivative of x for a given \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "def df_dy(x, y):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3aab5387f8bc8cf07a300c21c0d931e0",
     "grade": true,
     "grade_id": "tests_partial_derivatives",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: testa...\n",
    "sim.setup_grad_f(df_dx, df_dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.run(show_3d=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fråga 2\n",
    "\n",
    "- TODO: Fråga om hur minimipunkterna...\n",
    "- TODO: Fråga om höjdnivåskurvorna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "84c5be488b3a90bbfe1d5d4afd51b453",
     "grade": true,
     "grade_id": "q2",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kodkomplettering 3\n",
    "TODO: Använd snygg latex och förklara vad funktionen ska göra.\n",
    "TODO: Förklara hur man gör ett steg i gd och vad gamma innebär, samt tipsa om `np.linalg.norm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7c5bad9eeb278b48edd2c46ff638a920",
     "grade": false,
     "grade_id": "answer_gradient_descent_step",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "gamma = 0.2\n",
    "def gradient_descent_step(x, y):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return new_x, new_y, step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9c2343ddb76c13b743b032a51119af39",
     "grade": true,
     "grade_id": "tests_gradient_descent_step",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: testa\n",
    "sim.setup_gds(gradient_descent_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultat\n",
    "Med en funktion och dess partiella derivata tillgängliga, samt med förmåga att gå ett steg antiparallellt med gradienten, så är vi redo att testköra algoritmen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_points = [(2, 2)]\n",
    "\n",
    "sim.gd_trails = []\n",
    "for starting_point in starting_points:\n",
    "    x, y = starting_point\n",
    "    gd_trail = np.array([[x, y, f(x,y)]])\n",
    "    latest_step_length = np.inf\n",
    "\n",
    "    precision = 0.001\n",
    "    while latest_step_length > precision and len(gd_trail) <= 100:\n",
    "        x, y, latest_step_length = gradient_descent_step(x, y)\n",
    "        gd_trail = np.append(gd_trail, [[x, y, f(x,y)]], axis=0)\n",
    "\n",
    "    sim.gd_trails.append(gd_trail)\n",
    "    print('Ran GD from f({:.2f}, {:.2f})={:5.2f} to f({:.2f}, {:.2f})={:5.2f} after {} steps.'.format(*gd_trail[0,:], *gd_trail[-1,:], len(gd_trail)))\n",
    "\n",
    "sim.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fråga 3\n",
    "- TODO: Fråga: \n",
    "- TODO: Fråga: Undersök vad som händer med låg och hög step size multiplier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ec953bccaf694d373a34478a03e08725",
     "grade": true,
     "grade_id": "q3",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fortsättning\n",
    "\n",
    "Har du blivit intresserad av maskinlärning och artificiell intelligens? Här finns lite uppföljningstips.\n",
    "\n",
    "A.I. Experiments|Machine Learning Recipes|The Math of Intelligence\n",
    "-|-|-\n",
    "[![](https://img.youtube.com/vi/oOwfiYnRi5c/0.jpg)](https://www.youtube.com/watch?v=oOwfiYnRi5c&index=1&list=PLOU2XLYxmsIKubpTZNmgNKL6ToSQ1pWmy)|[![](https://img.youtube.com/vi/cKxRvEZd3Mw/0.jpg)](https://www.youtube.com/watch?v=cKxRvEZd3Mw&index=1&list=PLRAcvynLm0SCOJ7Ik3Q58-DTOKgY5h0Ky)|[![](https://img.youtube.com/vi/xRJCOz3AfYY/0.jpg)](https://www.youtube.com/watch?v=xRJCOz3AfYY&index=1&list=PL2-dafEMk2A7mu0bSksCGMJEmeddU_H4D)\n",
    "*YouTube playlist: Introduktion till möjligheter inom ML.*|*YouTube playlist: Praktiskt hur ML går till.*|*YouTube playlist: Teoretiskt om matematiken i ML.*\n",
    "\n",
    "Python - Basics|Python - Intermediate|Python - Machine Learning\n",
    "-|-|-\n",
    "[![](https://img.youtube.com/vi/IX6mc9l6tY4/0.jpg)](https://pythonprogramming.net/introduction-to-python-programming/)|[![](https://img.youtube.com/vi/YSe9Tu_iNQQ/0.jpg)](https://pythonprogramming.net/introduction-intermediate-python-tutorial/)|[![](https://img.youtube.com/vi/OGxgnH8y2NM/0.jpg)](https://pythonprogramming.net/machine-learning-tutorial-python-introduction/)\n",
    "*Kurs och YouTube playlist: En grundkurs i Python.*|*Kurs och YouTube playlist: En fortsättningskurs i Python.*|*Kurs och YouTube playlist: En grundkurs i ML.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
