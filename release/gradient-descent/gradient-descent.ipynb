{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General instructions\n",
    "\n",
    "#### Regarding notebooks.azure.com\n",
    "\n",
    "> __Preview / Edit__: You will be in preview mode unless you have made a copy of the notebook.\n",
    "\n",
    "> __Clone__: To get your own copy of the notebook and associated files, press clone and login.\n",
    "\n",
    "#### Regarding Jupyter Notebooks\n",
    "\n",
    "> __Markdown cells__: This cell is a [markdown](http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html) cell, you can edit it by doubleclicking on it and render it again by pressing __Shift + Enter__. \n",
    "\n",
    "> __Code cells__: Code cells contain Python code, and can be run by pressing __Shift + Enter__. Code output shows up in an associated *output cell* below.\n",
    "\n",
    "#### Regarding these projects\n",
    "\n",
    "> __Questions__: You are supposed to answer questions, enter your answers in the markdown with the text YOUR ANSWER HERE.\n",
    "\n",
    "> __Implementations__: You are supposed to implement code according to instructions, where it sais `YOUR CODE HERE` (remove \"`raise NotImplementedError()`\" when you do).\n",
    "\n",
    "> __Finishing touches__: Before you submit your project.\n",
    "1. Enter NAME and COLLABORATORS below.\n",
    "2. Rerun the code by clicking **Kernel$\\rightarrow$Restart & Run All**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kodlabb - Algoritmen *gradient descent*\n",
    "\n",
    "## Förkunskaper\n",
    "- Derivata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bakgrund och inspiration\n",
    "En dator lyder instruktioner till punkt och pricka. Men vad händer om en dator ombeds att träna upp en förmåga att ta egna beslut? Det är just det som maskininlärning (ML) och artificiell intelligens (AI) handlar om. AI tränas ofta genom att minimera någon form av fel den gör och *gradient descent* (GD) som vi kommer kika på är en vanlig algoritm för detta. Titta på något exempel nedan och kom sedan tillbaka för att lära dig mer!\n",
    "\n",
    "|Elon Musk's 'Dota 2' Experiment is Disrupting Esports in a Big Way|Meet the dazzling flying machines of the future|\n",
    "|:-|:-|\n",
    "|[![](https://img.youtube.com/vi/jAu1ZsTCA64/0.jpg)](https://www.youtube.com/watch?v=jAu1ZsTCA64)|[![](https://img.youtube.com/vi/RCXGpEmFbOw/0.jpg)](https://www.youtube.com/watch?v=RCXGpEmFbOw)|\n",
    "|*YouTube: En artificiell intelligens har besegrat Dota2 proffs i dueller (Augusti 2017).*|*YouTube: De flesta quadrokoptrar styrs med hjälp av AI, tränad med ML.*|\n",
    "\n",
    "|Real-Time Facial Expression Transfer|A.I. Experiments: Giorgio Cam|\n",
    "|:-|:-|\n",
    "|[![](https://img.youtube.com/vi/mkI6qfpEJmI/0.jpg)](https://www.youtube.com/watch?v=mkI6qfpEJmI)|[![](https://img.youtube.com/vi/eKeI63VSpto/0.jpg)](https://www.youtube.com/watch?v=eKeI63VSpto&list=PLOU2XLYxmsIKubpTZNmgNKL6ToSQ1pWmy&index=2)|\n",
    "|*YouTube: En AI har lärt sig att låtsas koppla en skådespelares ansiktsuttryck till ett annat ansikte enbart med hjälp av videomaterial på personerna.*|*YouTube: Mjukvara kan smidigt använda sig av AI tillgänglig över internet för att känna igen föremål i bilder, översätta språk och mycket mera.*|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fråga 1 (Frivillig)\n",
    "\n",
    "* Blev du inspirerad? Dela gärna med dig om dina tankar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "887e9c121e022c1fdecb5ac17e02995b",
     "grade": true,
     "grade_id": "thoughts",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "### Answer\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementering\n",
    "Låt oss komma igång och börja koda lite, målet för denna kodlabb är att lära oss om och testa på *gradient descent* (GD). Algoritmen hjälper oss att hitta en funktions minimipunkter, och i praktiken kan detta innebära att en AI blir smartare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kodkomplettering 1\n",
    "Vi behöver en funktion med ett antal minimipunkter att testa algoritmen på.\n",
    "\n",
    "Definiera pythonfunktion `f` så att den beter sig precis som den matematiska funktionen $f(x, y)$ nedan. Använd dig av `numpy` bibliotekets funktioner `np.sin`, `np.cos` och `np.exp` tillsammans med Pythons `**` operator (`x**2`$=x^2$).\n",
    "\n",
    "$$f(x, y) = \\sin(\\,({\\frac{x}{2}-2})^2 + (\\frac{y}{2}-2)^2\\,) \\cdot \\cos(\\,x-y+e^{-y}\\,)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from simulation import Sim\n",
    "sim = Sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5aed77d4a52f9de6f2cc5ab035269b5c",
     "grade": false,
     "grade_id": "answer_function_definition",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    \"\"\"The function to investigate described above, that returns a value for all numerical inputs x and y.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "20fcd87d4f00b5c77ce708e6eb970b35",
     "grade": true,
     "grade_id": "tests_function_definition",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sim.setup_f(f)\n",
    "sim.run(show_2d=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studiestund 1\n",
    "\n",
    "Innan vi fortsätter behöver vi utvidga våra kunskaper från Matte 3 och lära oss om *funktioner av flera variabler*, *partiell derivata* och *gradienter*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Funktioner av flera variabler, partiell derivata och gradienter\n",
    "\n",
    "En *definitionsmängd* eller en *domän* är inom matematiken är mängden av alla möjliga invärden för en funktion. Ibland har funktioner flera invärden, den tar med andra ord emot flera variabler. Exempel på sådanna funktioner är $g$ och $h$ nedan - deras definitionsmängder är två- respektive tredimensionella.\n",
    "\n",
    "\\begin{align}\n",
    "f(x)     & = x^2         & f(2)     & = 4  \\\\\n",
    "g(x,y)   & = x^2+y^2     & f(2,3)   & = 13 \\\\\n",
    "h(x,y,z) & = x^2+y^2+z^2 & f(2,3,4) & = 29 \\\\\n",
    "\\end{align}\n",
    "\n",
    "Ibland är det bra att veta hur funktionsvärdet förändras om vi förflyttar oss i definitionsmängden. För varje riktning vi kan röra oss inom definitionsmängden kan vi beräkna en *partiell derivata*. En *gradient* är en vektor vars komponenter består av de partiella derivatorna. Titta nu på följande film och besvara därefter några kontrollfrågor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Gradients and Partial Derivatives|\n",
    "|:-|\n",
    "|[![](https://img.youtube.com/vi/GkB4vW16QHI/0.jpg)](https://www.youtube.com/watch?v=GkB4vW16QHI)|\n",
    "|*YouTube: Lär dig om [partiell derivata](https://sv.wikipedia.org/wiki/Partiell_derivata) och [gradientvektorer](https://sv.wikipedia.org/wiki/Gradient) $\\nabla f = (\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y})$*|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fråga 2\n",
    "I bilden ovan ser vi en funktion $z=f(x, y)$ representerad som en yta. Föreställ dig att du är en myra på den ytan.\n",
    "- a) Beskriv vart du skulle gå om du följde gradienten och stod i en backe.\n",
    "- b) Beskriv vart du skulle gå om du följde gradienten och stod på en kulles topp.\n",
    "- c) Beskriv vad det engelska ordet *descent* betyder och gissa hur algoritmen *gradient descent* fungerar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5f1771fb3ae63396e9d8e13939b1d51b",
     "grade": true,
     "grade_id": "gradient_conceptuality",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "### Answer\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kodkomplettering 2\n",
    "*Gradient descent* bygger på att vi kan promenera antiparallellt (åt andra hållet) till gradienten, och gradienten som är en vektor, kan bestämmas om vi känner till de partiella derivatorna. Vi kan beräkna de partiella derivatorna ungefärligt med ett litet värde på $h$ på följande sätt.\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x} \\approx \\frac{f(x+h, y) - f(x-h, y)}{2h}$$\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial y} \\approx \\frac{f(x, y+h) - f(x, y-h)}{2h}$$\n",
    "\n",
    "Vi använder oss av en så kallad *central differenskvot* - central eftersom vi tittar på ett funktionsvärde till både vänster och höger om en punkt, och differenskvot för att det är en kvot vars täljare och nämnare består av differenser. Centrala differenskvoter är lämpliga att använda för att uppskatta derivata numeriskt.\n",
    "\n",
    "Ditt uppdrag är att komplettera funktionerna nedan, så att de numeriskt beräknar de partiella derivatorna för funktionen `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d46257dbefc37d225f6b96a858743783",
     "grade": false,
     "grade_id": "answer_partial_derivatives",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "h = 0.001\n",
    "def df_dx(x, y):\n",
    "    \"\"\"Return an approximate value for the partial derivative of the function f with respect to x, as described above.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "def df_dy(x, y):\n",
    "    \"\"\"Return an approximate value for the partial derivative of the function f with respect to y, as described above.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9a2d0cdb7a99fc2534eb85aa98c3b260",
     "grade": true,
     "grade_id": "tests_partial_derivatives",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sim.setup_grad_f(df_dx, df_dy)\n",
    "sim.run(show_3d=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fråga 4\n",
    "Ovan ser du förhoppningsvis nu ett [färgdiagram](https://sv.wikipedia.org/wiki/F%C3%A4rgdiagram) (Heat map) där röda färger motsvarar höga funktionsvärden och blåa färger motsvarar låga. I diagrammet finns även [konturlinjer (också kallat *isaritmer* och *isolinjer*)](https://sv.wikipedia.org/wiki/Isaritm).\n",
    "\n",
    "* a) Vad tror du pilarna motsvarar i bilden ovan?\n",
    "* b) Beskriv hur pilarna pekar kring minimi- och maximipunkterna.\n",
    "* c) Om du gjort rätt kommer pilarna inte peka längst med konturlinjerna, varför inte?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "1b457310529be71031305450a0b78a2c",
     "grade": true,
     "grade_id": "cell-f06c84cb821ed24e",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "### Answer\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studiestund 2\n",
    "\n",
    "Nu är det dags att vi lär oss mer om GD algoritmen, den är alltså till för att hitta minimipunkter för funktioner. Detta är betydelsefullt för träningen av AI, de tränas ofta genom att minimera så kallade *cost functions* som motsvarar hur mycket misstag de gör.\n",
    "\n",
    "I den andra filmen nedan förklaras idén med gradient descent mellan 5:21 och 12:18. Om du vill kan du såklart titta på båda filmerna som är de två första delarna i en serie om så kallade neurala nätverk, men det är överkurs.\n",
    "\n",
    "But what *is* a neural network? &#124; Deep learning, Part 1|Gradient descent, how neural networks learn &#124; Deep learning, Part 2\n",
    ":-|:-\n",
    "[![](https://img.youtube.com/vi/aircAruvnKk/maxresdefault.jpg)](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=1)|[![](https://img.youtube.com/vi/IHZwWFHWa-w/maxresdefault.jpg)](https://www.youtube.com/watch?v=IHZwWFHWa-w&index=2&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&t=5m21s)\n",
    "*YouTube: Del 1 i serien om neurala nätverk.*|*YouTube: Från 5:21 till 12:18 i filmen får du lära dig det du behöver veta om algoritmen gradient descent. Del 2 i serien om neurala nätverk.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fråga 3\n",
    "* a) GD hjälper oss att hitta en lokal minimipunkt, är det möjligt att finna en globala minimipunkt?\n",
    "* b) Låt oss anta att du känner till gradienten av funktionen för en punkt där du är nu, åt vilket håll i definitionsmängden bör du försöka gå för att hitta en minimipunkt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9750733fba8aeb0a3c770f8a115dbc91",
     "grade": true,
     "grade_id": "gradient_descent",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "### Answer\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kodkomplettering 3\n",
    "\n",
    "Du ska nu skapa en funktion som föreslår *ett* steg att gå i definitionsmängden av funktionen f som tar dig närmare en minimipunkt på följande sätt. Funktionen ska även räkna ut hur långt steget var, detta kan göras med pythagoras sats och `np.sqrt`. Vill du så kan du använda [`np.linalg.norm`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linalg.norm.html) för att räkna ut steglängden.\n",
    "\n",
    "\\begin{align}\n",
    "\\text{new_x} \\gets x - \\alpha \\cdot \\frac{\\partial f}{\\partial x}(x, y)\\\\\n",
    "\\\\\n",
    "\\text{new_y} \\gets y - \\alpha \\cdot \\frac{\\partial f}{\\partial y}(x, y)\\\\\n",
    "\\end{align}\n",
    "\n",
    " $\\alpha$ (alpha) är en så kallad *step size multiplier*, och kallas ofta för *the learning rate*, ett högt alpha värde gör att vi raskt rör oss mot minimipunkten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0244daa96e1c62501aac9cd3bf0e123c",
     "grade": false,
     "grade_id": "answer_gradient_descent_step",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "def gradient_descent_step(x, y, alpha=alpha):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return new_x, new_y, step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "80c61e086421814b6071a4332bbc93c7",
     "grade": true,
     "grade_id": "tests_gradient_descent_step",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sim.setup_gds(gradient_descent_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultat\n",
    "Låt oss testköra algoritmen med hjälp av det du gjort hittills!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with these values\n",
    "starting_points = [(2, 2)] # TODO: Add three more starting points and find all four minima in between (0,0) and (5,5)\n",
    "alpha = 0.2                # TODO: Experiment with a higher value and interperate the results.\n",
    "min_step_size = 0.001\n",
    "max_steps = 100\n",
    "\n",
    "# Runs GD until our steps becomes too small (< min_step_size) or we have taken the maximum amount of steps\n",
    "sim.gd_trails = []\n",
    "for starting_point in starting_points:\n",
    "    x, y = starting_point\n",
    "    gd_trail = np.array([[x, y, f(x,y)]])\n",
    "    latest_step_length = np.inf\n",
    "\n",
    "    while latest_step_length > min_step_size and len(gd_trail) <= max_steps:\n",
    "        x, y, latest_step_length = gradient_descent_step(x, y, alpha=alpha)\n",
    "        gd_trail = np.append(gd_trail, [[x, y, f(x,y)]], axis=0)\n",
    "\n",
    "    sim.gd_trails.append(gd_trail)\n",
    "    print('Ran GD from f({:.2f}, {:.2f})={:5.2f} to f({:.2f}, {:.2f})={:5.2f} after {} steps.'.format(*gd_trail[0,:], *gd_trail[-1,:], len(gd_trail)))\n",
    "\n",
    "sim.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fråga 5\n",
    "Undersök på egen hand och försök besvara följande frågor.\n",
    "\n",
    "- a) Det finns fyra lokala minimipunkter mellan (0,0) och (5,5) - vilken har högst funktionsvärde? ( $f(x,y)=z$ )\n",
    "- b) Vad som kan hända om variabeln `alpha` är för högt?\n",
    "- c) Vad är nackdelarna av att ha för låga respektive för höga värden på `min_step_size`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "79f4d57300a808a68e89bb7d932877b4",
     "grade": true,
     "grade_id": "exploration",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "### Answer\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vill du lära dig mer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Använd befintlig AI\n",
    "Du behöver inte lära dig ML och träna din egen AI - du kan använda befintlig AI genom av fritt tillgängliga [APIer](https://sv.wikipedia.org/wiki/Application_Programming_Interface).\n",
    "\n",
    "|A.I. Experiments|Getting Started in 3 Minutes with API.AI|\n",
    "|:-|:-|\n",
    "|[![](https://img.youtube.com/vi/oOwfiYnRi5c/0.jpg)](https://www.youtube.com/watch?v=oOwfiYnRi5c&list=PLOU2XLYxmsIKubpTZNmgNKL6ToSQ1pWmy)|[![](https://img.youtube.com/vi/Om7tyGGemXI/0.jpg)](https://www.youtube.com/watch?v=Om7tyGGemXI)\n",
    "|*YouTube playlist: Flera av apparna som demonstreras använder sig av APIer.*|*YouTube: api.ai hjälper din mjukvara att ta beslut utifrån vad användaren säger.*|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python\n",
    "Alla programmeringsspråk kan använda ML, men det är till Python som det utvecklas mest spännande stödbibliotek just nu.\n",
    "\n",
    "Python - Basics|Python - Intermediate\n",
    ":-|:-\n",
    "[![](https://img.youtube.com/vi/IX6mc9l6tY4/0.jpg)](https://pythonprogramming.net/introduction-to-python-programming/)|[![](https://img.youtube.com/vi/YSe9Tu_iNQQ/0.jpg)](https://pythonprogramming.net/introduction-intermediate-python-tutorial/)\n",
    "*Kurs och YouTube playlist: En grundkurs i Python.*|*Kurs och YouTube playlist: En fortsättningskurs i Python.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grunderna i ML\n",
    "Vill du använda ML för att träna en AI på egen hand? Då kan vara bra att börja här. Skapa dig en en översikt av ML innan du beger sig in i de mer avancerade teknikerna och lär dig vad *Supervised* respektive *Unsupervised learning* innebär exempelvis. I dessa filmer stöter du på grundtekniker såsom *linear regression*, *support vector machines*, *decision trees* med mera.\n",
    "\n",
    "Python - Machine Learning|Machine Learning Recipes\n",
    ":-|:-\n",
    "[![](https://img.youtube.com/vi/OGxgnH8y2NM/0.jpg)](https://pythonprogramming.net/machine-learning-tutorial-python-introduction/)|[![](https://img.youtube.com/vi/cKxRvEZd3Mw/0.jpg)](https://www.youtube.com/watch?v=cKxRvEZd3Mw&list=PLRAcvynLm0SCOJ7Ik3Q58-DTOKgY5h0Ky)\n",
    "*Kurs och YouTube playlist: En grundkurs i ML.*|*YouTube playlist: Kort och praktiskt - en kokbok för ML.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avancerat: Neurala nätverk, *deep learning* och matematik\n",
    "Det finns många varianter av ML, och de har sina styrkor och svagheter. Neurala nätverk ligger som grund till några av de mest avancerade ML teknikerna i skrivande stund.\n",
    "\n",
    "Neural networks|The Math of Intelligence\n",
    ":-|:-\n",
    "[![](https://img.youtube.com/vi/aircAruvnKk/0.jpg)](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)|[![](https://img.youtube.com/vi/xRJCOz3AfYY/0.jpg)](https://www.youtube.com/watch?v=xRJCOz3AfYY&list=PL2-dafEMk2A7mu0bSksCGMJEmeddU_H4D)\n",
    "*YouTube playlist: Ger insikt om neurala nätverk.*|*YouTube playlist: Teoretiskt om matematiken i ML.*\n",
    "\n",
    "Neural Networks Demystified|Learning To See\n",
    ":-|:-\n",
    "[![](https://img.youtube.com/vi/bxe2T-V8XRs/0.jpg)](https://www.youtube.com/watch?v=bxe2T-V8XRs&list=PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU)|[![](https://img.youtube.com/vi/i8D90DkCLhI/0.jpg)](https://www.youtube.com/watch?v=i8D90DkCLhI&list=PLiaHhY2iBX9ihLasvE8BKnS2Xg8AhY6iV)\n",
    "*YouTube playlist: Ger teknisk och matematisk bakom hur neurala nätverk fungerar.*|*YouTube playlist: Om utmaningar och lösningar för att träna en dator att räkna fingrar.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
